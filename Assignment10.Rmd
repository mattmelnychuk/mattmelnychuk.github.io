
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 10: Predictive Modeling - Part 1"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](fa2021_assignment10.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Install the package `mlbench` and use the follows to import the data

```{r}
library(mlbench)
data(PimaIndiansDiabetes)
df <- PimaIndiansDiabetes
```

- Set seed to be 2020. 
- The target variable is `diabetes`
- Partition the data into 80% training and 20% testing.  

```{r}
# The target variable is the variable at column 9. 
names(df)[9] <- 'target'
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]

```


-------

2. Practice Decision Tree.  Do the follows:

  - Use `rpart` package, create a decision tree with maximum depth of 3. 
```{r}
df$target <- factor(df$target)
library(rpart)
tree_model <- rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 3))
```
  
  
  - Calculate the accuracy of the model on the testing data. 
```{r}
#predict on testing data
pred <- predict(tree_model, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
tree3pred <-cm$overall[1]
#72.5% accurate
```
  
  - Plot the tree
```{r}
library(rattle)
fancyRpartPlot(tree_model)
```
  
  
  - Plot the variable importance by the tree
```{r}
tree_model$variable.importance
barplot(tree_model$variable.importance)
```
  

-------

3. Practice Random Forest.  Do the follows: 

  - Use `randomForest` package, create a random forest of 1000 trees. 
```{r}
library(randomForest)
names(df)[9] <- 'target'
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)


```
  
  
  - Calculate the accuracy of the model on the testing data. 
```{r}
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
```
  
  - Plot the variable importance by the forest
  
```{r}
importance(forest_model)
barplot(importance(forest_model))
```

-------

4. Compare the testing accuracy of a forest of 1000 trees and a forest of 2000 trees. 
```{r}
library(randomForest)
names(df)[9] <- 'target'
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
forest1kpred <-cm$overall[1]

library(randomForest)
names(df)[9] <- 'target'
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
forest_model = randomForest(target ~ ., data=df_train, ntree = 2000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
forest2kpred <-cm$overall[1]

forest1kpred
forest2kpred

```



-------

5. Using Caret, create a tree with maximum depth of 3 and forest of 1000 trees. Compare the accuracy of these two models.
```{r}
set.seed(2020)
model1 <- train(target~., data=df_train, 
                method = "rpart2",
                maxdepth=3)
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
mod1pred <-cm$overall[1]

set.seed(2020)
model2 <- train(target~., data=df_train, 
                method = "rf",
                ntree = 1000) 
pred <- predict(model2, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
mod2pred<-cm$overall[1]

mod1pred
mod2pred
#Model 2 (the random forest) predicts better than the single decision tree
```


-------

6. Plot variable importance by the two models in 5. 
```{r}
# Tree
varImp(model1)
#Forest
varImp(model2)

#Plots below
plot(varImp(model1))
plot(varImp(model2))
```


-------

7. (Optional - For extra credits only) Use your own selected data.  Do the follows. 

```{r}
library(tidyverse)
library(ggplot2)
df7 <-read_csv("C:/Users/student/Desktop/Data Mining 460/ncaaVB.csv")
df7 <- select(df7,-School)
```

- Handle missing values if any 
```{r}
sum(is.na(df7))
#There are no missing values in this dataset
```


- Put the variables in the right format (categorical vs. continuous)
- Select a binary target variable (Use can create a binary target variable from a continuous variable). 

```{r}
library(randomForest)
names(df7)[25] <- 'target'
df7$target <- factor(df7$target)
df7$Conference <- factor(df7$Conference)
df7$Region <- factor(df7$Region)
df7$CoachLength <- factor(df7$CoachLength)

```


- Using caret with method `ranger` to train then test the accuracy of a random forest of 1000 trees. 
```{r}
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df7$target, p = .75, 
                                  list = FALSE)
df_train <- df7[ splitIndex,]
df_test <- df7[-splitIndex,]

model2 <- train(target~., data=df_train, 
                method = "rf",
                ntree = 1000) 
pred <- predict(model2, df_test)

cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]

varImp(model2)
#Hitting percentage,CoachWL, and WinPercent are the most useful at predicting if a team was in the playoffs in the previous year (the data doesn't have a value for if the team made the playoffs in the current year, so not the best thing to try to predict, but it works for demonstration purposes).
```
